{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "947e2dba-a73f-4e33-be58-680936eedc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a81da0b-2db7-410b-b64c-489a525a065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.458574</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.800503</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.642455</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.072174</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.067179</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.159400</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.240046</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.242831</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>USS Barnett\\nFPO AP 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.197226</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.109472</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>60567.944140</td>\n",
       "      <td>7.830362</td>\n",
       "      <td>6.137356</td>\n",
       "      <td>3.46</td>\n",
       "      <td>22837.361035</td>\n",
       "      <td>1.060194e+06</td>\n",
       "      <td>USNS Williams\\nFPO AP 30153-7653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>78491.275435</td>\n",
       "      <td>6.999135</td>\n",
       "      <td>6.576763</td>\n",
       "      <td>4.02</td>\n",
       "      <td>25616.115489</td>\n",
       "      <td>1.482618e+06</td>\n",
       "      <td>PSC 9258, Box 8489\\nAPO AA 42991-3352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>63390.686886</td>\n",
       "      <td>7.250591</td>\n",
       "      <td>4.805081</td>\n",
       "      <td>2.13</td>\n",
       "      <td>33266.145490</td>\n",
       "      <td>1.030730e+06</td>\n",
       "      <td>4215 Tracy Garden Suite 076\\nJoshualand, VA 01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>68001.331235</td>\n",
       "      <td>5.534388</td>\n",
       "      <td>7.130144</td>\n",
       "      <td>5.44</td>\n",
       "      <td>42625.620156</td>\n",
       "      <td>1.198657e+06</td>\n",
       "      <td>USS Wallace\\nFPO AE 73316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>65510.581804</td>\n",
       "      <td>5.992305</td>\n",
       "      <td>6.792336</td>\n",
       "      <td>4.07</td>\n",
       "      <td>46501.283803</td>\n",
       "      <td>1.298950e+06</td>\n",
       "      <td>37778 George Ridges Apt. 509\\nEast Holly, NV 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0         79545.458574             5.682861                   7.009188   \n",
       "1         79248.642455             6.002900                   6.730821   \n",
       "2         61287.067179             5.865890                   8.512727   \n",
       "3         63345.240046             7.188236                   5.586729   \n",
       "4         59982.197226             5.040555                   7.839388   \n",
       "...                ...                  ...                        ...   \n",
       "4995      60567.944140             7.830362                   6.137356   \n",
       "4996      78491.275435             6.999135                   6.576763   \n",
       "4997      63390.686886             7.250591                   4.805081   \n",
       "4998      68001.331235             5.534388                   7.130144   \n",
       "4999      65510.581804             5.992305                   6.792336   \n",
       "\n",
       "      Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                             4.09     23086.800503  1.059034e+06   \n",
       "1                             3.09     40173.072174  1.505891e+06   \n",
       "2                             5.13     36882.159400  1.058988e+06   \n",
       "3                             3.26     34310.242831  1.260617e+06   \n",
       "4                             4.23     26354.109472  6.309435e+05   \n",
       "...                            ...              ...           ...   \n",
       "4995                          3.46     22837.361035  1.060194e+06   \n",
       "4996                          4.02     25616.115489  1.482618e+06   \n",
       "4997                          2.13     33266.145490  1.030730e+06   \n",
       "4998                          5.44     42625.620156  1.198657e+06   \n",
       "4999                          4.07     46501.283803  1.298950e+06   \n",
       "\n",
       "                                                Address  \n",
       "0     208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...  \n",
       "1     188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
       "2     9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
       "3                             USS Barnett\\nFPO AP 44820  \n",
       "4                            USNS Raymond\\nFPO AE 09386  \n",
       "...                                                 ...  \n",
       "4995                   USNS Williams\\nFPO AP 30153-7653  \n",
       "4996              PSC 9258, Box 8489\\nAPO AA 42991-3352  \n",
       "4997  4215 Tracy Garden Suite 076\\nJoshualand, VA 01...  \n",
       "4998                          USS Wallace\\nFPO AE 73316  \n",
       "4999  37778 George Ridges Apt. 509\\nEast Holly, NV 2...  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('USA_Housing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a611a29-6d80-40b2-be01-3ea3bda2d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
       "       'Avg. Area Number of Bedrooms', 'Area Population', 'Price', 'Address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acc3dc58-90de-4153-94f6-35b8e9a2cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Avg. Area Income              5000 non-null   float64\n",
      " 1   Avg. Area House Age           5000 non-null   float64\n",
      " 2   Avg. Area Number of Rooms     5000 non-null   float64\n",
      " 3   Avg. Area Number of Bedrooms  5000 non-null   float64\n",
      " 4   Area Population               5000 non-null   float64\n",
      " 5   Price                         5000 non-null   float64\n",
      " 6   Address                       5000 non-null   object \n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba3c4e6b-7dc0-4aab-987c-334631ac6400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68583.108984</td>\n",
       "      <td>5.977222</td>\n",
       "      <td>6.987792</td>\n",
       "      <td>3.981330</td>\n",
       "      <td>36163.516039</td>\n",
       "      <td>1.232073e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10657.991214</td>\n",
       "      <td>0.991456</td>\n",
       "      <td>1.005833</td>\n",
       "      <td>1.234137</td>\n",
       "      <td>9925.650114</td>\n",
       "      <td>3.531176e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17796.631190</td>\n",
       "      <td>2.644304</td>\n",
       "      <td>3.236194</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>172.610686</td>\n",
       "      <td>1.593866e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>61480.562388</td>\n",
       "      <td>5.322283</td>\n",
       "      <td>6.299250</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>29403.928702</td>\n",
       "      <td>9.975771e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68804.286404</td>\n",
       "      <td>5.970429</td>\n",
       "      <td>7.002902</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>36199.406689</td>\n",
       "      <td>1.232669e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75783.338666</td>\n",
       "      <td>6.650808</td>\n",
       "      <td>7.665871</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>42861.290769</td>\n",
       "      <td>1.471210e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>107701.748378</td>\n",
       "      <td>9.519088</td>\n",
       "      <td>10.759588</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>69621.713378</td>\n",
       "      <td>2.469066e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "count       5000.000000          5000.000000                5000.000000   \n",
       "mean       68583.108984             5.977222                   6.987792   \n",
       "std        10657.991214             0.991456                   1.005833   \n",
       "min        17796.631190             2.644304                   3.236194   \n",
       "25%        61480.562388             5.322283                   6.299250   \n",
       "50%        68804.286404             5.970429                   7.002902   \n",
       "75%        75783.338666             6.650808                   7.665871   \n",
       "max       107701.748378             9.519088                  10.759588   \n",
       "\n",
       "       Avg. Area Number of Bedrooms  Area Population         Price  \n",
       "count                   5000.000000      5000.000000  5.000000e+03  \n",
       "mean                       3.981330     36163.516039  1.232073e+06  \n",
       "std                        1.234137      9925.650114  3.531176e+05  \n",
       "min                        2.000000       172.610686  1.593866e+04  \n",
       "25%                        3.140000     29403.928702  9.975771e+05  \n",
       "50%                        4.050000     36199.406689  1.232669e+06  \n",
       "75%                        4.490000     42861.290769  1.471210e+06  \n",
       "max                        6.500000     69621.713378  2.469066e+06  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fc456e9-03d1-453f-b784-303313d34a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
    "               'Avg. Area Number of Bedrooms', 'Area Population']]\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0fc6f40-27c2-4c79-a4c1-8375c53286b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dc780a5-d825-4de7-ba8e-83647e50d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "312c69b1-614b-4c62-8fd7-41744e83c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "945e59e0-988d-4b1a-9793-e87c5556cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4362f8b-b484-4a39-91a6-6f5baa5f4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45aa9514-5236-4427-8114-c120be8d8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9417c8c8-4759-47cf-b379-c5d5923d00e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6869fc2f-b43f-4828-9440-b29d16ccf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b75e2263-628a-4b16-b50f-83cf9c027b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(Dense(500,activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "972bd7dd-84d0-49ac-af5a-ed212e005a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1633168916480.0000 - val_loss: 1680525230080.0000\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1632934952960.0000 - val_loss: 1679986655232.0000\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1631885590528.0000 - val_loss: 1678124253184.0000\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1629031497728.0000 - val_loss: 1673781051392.0000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1623171268608.0000 - val_loss: 1665706622976.0000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1613092487168.0000 - val_loss: 1652671905792.0000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1597573169152.0000 - val_loss: 1633467891712.0000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1575697514496.0000 - val_loss: 1607144570880.0000\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1546416685056.0000 - val_loss: 1572866621440.0000\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1509138628608.0000 - val_loss: 1530166116352.0000\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1463313629184.0000 - val_loss: 1478422560768.0000\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1408639959040.0000 - val_loss: 1417526247424.0000\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1345103724544.0000 - val_loss: 1347910107136.0000\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1273170493440.0000 - val_loss: 1269643476992.0000\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1193491562496.0000 - val_loss: 1184217300992.0000\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1107221676032.0000 - val_loss: 1092627070976.0000\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1015840374784.0000 - val_loss: 996485234688.0000\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 920618598400.0000 - val_loss: 897460994048.0000\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 823784964096.0000 - val_loss: 798082203648.0000\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 727088300032.0000 - val_loss: 699551514624.0000\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 632788090880.0000 - val_loss: 604375220224.0000\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 542662393856.0000 - val_loss: 514442592256.0000\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 458321494016.0000 - val_loss: 432134586368.0000\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 381773348864.0000 - val_loss: 358021595136.0000\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 314564345856.0000 - val_loss: 293699354624.0000\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 256715997184.0000 - val_loss: 239066529792.0000\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 208876011520.0000 - val_loss: 194692808704.0000\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 170405527552.0000 - val_loss: 160099958784.0000\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 140732661760.0000 - val_loss: 133135892480.0000\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 118424322048.0000 - val_loss: 113468391424.0000\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 102352117760.0000 - val_loss: 99630514176.0000\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 91299708928.0000 - val_loss: 90007977984.0000\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 83854475264.0000 - val_loss: 83619520512.0000\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 78998159360.0000 - val_loss: 79551471616.0000\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 75983069184.0000 - val_loss: 77053542400.0000\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 74120593408.0000 - val_loss: 75410685952.0000\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 72940986368.0000 - val_loss: 74347249664.0000\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 72233246720.0000 - val_loss: 73698656256.0000\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 71780302848.0000 - val_loss: 73264635904.0000\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 71496712192.0000 - val_loss: 72964587520.0000\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 71285374976.0000 - val_loss: 72728862720.0000\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 71119847424.0000 - val_loss: 72556339200.0000\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70981574656.0000 - val_loss: 72369643520.0000\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70835814400.0000 - val_loss: 72236244992.0000\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70705225728.0000 - val_loss: 72087707648.0000\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70580551680.0000 - val_loss: 71937335296.0000\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70452240384.0000 - val_loss: 71799332864.0000\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70321061888.0000 - val_loss: 71666155520.0000\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 70187819008.0000 - val_loss: 71537442816.0000\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 70055337984.0000 - val_loss: 71401734144.0000\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 69920825344.0000 - val_loss: 71258947584.0000\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 69792710656.0000 - val_loss: 71134322688.0000\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 69646368768.0000 - val_loss: 70987309056.0000\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 69506129920.0000 - val_loss: 70845751296.0000\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 69366898688.0000 - val_loss: 70685892608.0000\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 69223710720.0000 - val_loss: 70536527872.0000\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 69080702976.0000 - val_loss: 70407462912.0000\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68934868992.0000 - val_loss: 70265954304.0000\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68782456832.0000 - val_loss: 70096453632.0000\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68635426816.0000 - val_loss: 69936111616.0000\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68487495680.0000 - val_loss: 69788844032.0000\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68338458624.0000 - val_loss: 69626445824.0000\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68191834112.0000 - val_loss: 69477548032.0000\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 68026855424.0000 - val_loss: 69328707584.0000\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 67874418688.0000 - val_loss: 69165170688.0000\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 67719733248.0000 - val_loss: 68994408448.0000\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 67570470912.0000 - val_loss: 68841185280.0000\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 67414659072.0000 - val_loss: 68683063296.0000\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 67245842432.0000 - val_loss: 68492808192.0000\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 67090472960.0000 - val_loss: 68343336960.0000\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 66921832448.0000 - val_loss: 68175908864.0000\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 66758135808.0000 - val_loss: 68019695616.0000\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 66598023168.0000 - val_loss: 67854643200.0000\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 66429218816.0000 - val_loss: 67667251200.0000\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 66265944064.0000 - val_loss: 67498508288.0000\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 66097176576.0000 - val_loss: 67324227584.0000\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 65928036352.0000 - val_loss: 67172937728.0000\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 65759739904.0000 - val_loss: 66986053632.0000\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 65589383168.0000 - val_loss: 66810413056.0000\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 65415684096.0000 - val_loss: 66624217088.0000\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 65248337920.0000 - val_loss: 66475954176.0000\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 65077690368.0000 - val_loss: 66276737024.0000\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 64907026432.0000 - val_loss: 66129530880.0000\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 64727564288.0000 - val_loss: 65935716352.0000\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 64549834752.0000 - val_loss: 65751277568.0000\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 64382181376.0000 - val_loss: 65549127680.0000\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 64201089024.0000 - val_loss: 65371119616.0000\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 64024883200.0000 - val_loss: 65179582464.0000\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 63841243136.0000 - val_loss: 65017196544.0000\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 63674986496.0000 - val_loss: 64854794240.0000\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 63486865408.0000 - val_loss: 64649101312.0000\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 63320190976.0000 - val_loss: 64460218368.0000\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 63130443776.0000 - val_loss: 64297234432.0000\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 62971482112.0000 - val_loss: 64082264064.0000\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 62769197056.0000 - val_loss: 63903866880.0000\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 62581043200.0000 - val_loss: 63719636992.0000\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 62398033920.0000 - val_loss: 63521210368.0000\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 62213984256.0000 - val_loss: 63361753088.0000\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 62031839232.0000 - val_loss: 63142498304.0000\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 61845454848.0000 - val_loss: 62947237888.0000\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 61667745792.0000 - val_loss: 62765981696.0000\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 61474418688.0000 - val_loss: 62572199936.0000\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 61290819584.0000 - val_loss: 62382813184.0000\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 61114298368.0000 - val_loss: 62211604480.0000\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 60927115264.0000 - val_loss: 61989412864.0000\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 60724015104.0000 - val_loss: 61817765888.0000\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 60531609600.0000 - val_loss: 61620994048.0000\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 60344836096.0000 - val_loss: 61401145344.0000\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 60170575872.0000 - val_loss: 61195366400.0000\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 59955683328.0000 - val_loss: 61028843520.0000\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 59781496832.0000 - val_loss: 60805582848.0000\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 59579240448.0000 - val_loss: 60601155584.0000\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 59379884032.0000 - val_loss: 60429422592.0000\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 59185987584.0000 - val_loss: 60220280832.0000\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 58994241536.0000 - val_loss: 60036710400.0000\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 58806300672.0000 - val_loss: 59856601088.0000\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 58605260800.0000 - val_loss: 59624423424.0000\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 58414174208.0000 - val_loss: 59417464832.0000\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 58228154368.0000 - val_loss: 59214565376.0000\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 58029699072.0000 - val_loss: 58990837760.0000\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 57817501696.0000 - val_loss: 58831257600.0000\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 57616109568.0000 - val_loss: 58566291456.0000\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 57417490432.0000 - val_loss: 58373197824.0000\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 57218117632.0000 - val_loss: 58172440576.0000\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 57016139776.0000 - val_loss: 57991487488.0000\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 56812662784.0000 - val_loss: 57751298048.0000\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 56614342656.0000 - val_loss: 57567358976.0000\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 56439898112.0000 - val_loss: 57301934080.0000\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 56208388096.0000 - val_loss: 57112403968.0000\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 56005177344.0000 - val_loss: 56909021184.0000\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 55807512576.0000 - val_loss: 56746430464.0000\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 55593844736.0000 - val_loss: 56495353856.0000\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 55395803136.0000 - val_loss: 56275439616.0000\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 55184486400.0000 - val_loss: 56094724096.0000\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 54990503936.0000 - val_loss: 55874289664.0000\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 54772899840.0000 - val_loss: 55644114944.0000\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 54570840064.0000 - val_loss: 55430070272.0000\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 54367809536.0000 - val_loss: 55197097984.0000\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 54145560576.0000 - val_loss: 55015153664.0000\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 53939089408.0000 - val_loss: 54791553024.0000\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 53726433280.0000 - val_loss: 54569209856.0000\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 53537357824.0000 - val_loss: 54349832192.0000\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 53321117696.0000 - val_loss: 54157148160.0000\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 53088661504.0000 - val_loss: 53854359552.0000\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 52874375168.0000 - val_loss: 53650522112.0000\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 52671909888.0000 - val_loss: 53493112832.0000\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 52438925312.0000 - val_loss: 53235023872.0000\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 52246208512.0000 - val_loss: 52985487360.0000\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 51989504000.0000 - val_loss: 52861911040.0000\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 51795582976.0000 - val_loss: 52561461248.0000\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 51567878144.0000 - val_loss: 52318896128.0000\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 51351261184.0000 - val_loss: 52111302656.0000\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 51118485504.0000 - val_loss: 51813982208.0000\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 50904829952.0000 - val_loss: 51587424256.0000\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 50676551680.0000 - val_loss: 51411599360.0000\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 50462019584.0000 - val_loss: 51189538816.0000\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 50241179648.0000 - val_loss: 50898157568.0000\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 50012839936.0000 - val_loss: 50696765440.0000\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 49799925760.0000 - val_loss: 50416721920.0000\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 49577152512.0000 - val_loss: 50201542656.0000\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 49328001024.0000 - val_loss: 49977233408.0000\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 49095176192.0000 - val_loss: 49760419840.0000\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 48866574336.0000 - val_loss: 49514803200.0000\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 48639848448.0000 - val_loss: 49272594432.0000\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 48411361280.0000 - val_loss: 49055682560.0000\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 48171286528.0000 - val_loss: 48790589440.0000\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 47944835072.0000 - val_loss: 48520073216.0000\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 47693004800.0000 - val_loss: 48287727616.0000\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 47452979200.0000 - val_loss: 48059355136.0000\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 47216640000.0000 - val_loss: 47794610176.0000\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 46985674752.0000 - val_loss: 47516585984.0000\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 46737838080.0000 - val_loss: 47280963584.0000\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 46487597056.0000 - val_loss: 46982557696.0000\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 46249426944.0000 - val_loss: 46764339200.0000\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 45994442752.0000 - val_loss: 46479085568.0000\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 45736132608.0000 - val_loss: 46284226560.0000\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 45524078592.0000 - val_loss: 45982826496.0000\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 45247463424.0000 - val_loss: 45679894528.0000\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 44989493248.0000 - val_loss: 45457858560.0000\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 44744192000.0000 - val_loss: 45176307712.0000\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 44477276160.0000 - val_loss: 44934574080.0000\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 44237697024.0000 - val_loss: 44688760832.0000\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 43986653184.0000 - val_loss: 44381114368.0000\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 43709149184.0000 - val_loss: 44147814400.0000\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 43472896000.0000 - val_loss: 43845709824.0000\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 43192696832.0000 - val_loss: 43577532416.0000\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 42924998656.0000 - val_loss: 43296964608.0000\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 42683416576.0000 - val_loss: 42971602944.0000\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 42373763072.0000 - val_loss: 42782330880.0000\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 42124124160.0000 - val_loss: 42442739712.0000\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 41852919808.0000 - val_loss: 42170023936.0000\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 41579278336.0000 - val_loss: 41886941184.0000\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 41303117824.0000 - val_loss: 41602535424.0000\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 41017503744.0000 - val_loss: 41329451008.0000\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 40749944832.0000 - val_loss: 41054928896.0000\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 40471781376.0000 - val_loss: 40732332032.0000\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 40182841344.0000 - val_loss: 40461795328.0000\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 39902691328.0000 - val_loss: 40148856832.0000\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 39622000640.0000 - val_loss: 39820447744.0000\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 39331532800.0000 - val_loss: 39632101376.0000\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 39033356288.0000 - val_loss: 39244734464.0000\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 38749347840.0000 - val_loss: 38971240448.0000\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 38461566976.0000 - val_loss: 38635143168.0000\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 38162317312.0000 - val_loss: 38417342464.0000\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 37871742976.0000 - val_loss: 38021222400.0000\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 37609709568.0000 - val_loss: 37739970560.0000\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 37279891456.0000 - val_loss: 37451636736.0000\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 36977487872.0000 - val_loss: 37085233152.0000\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 36668166144.0000 - val_loss: 36821430272.0000\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 36358987776.0000 - val_loss: 36471185408.0000\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 36069720064.0000 - val_loss: 36150472704.0000\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 35777581056.0000 - val_loss: 35891740672.0000\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 35437268992.0000 - val_loss: 35515928576.0000\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 35149881344.0000 - val_loss: 35232247808.0000\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 34816282624.0000 - val_loss: 34870779904.0000\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 34511749120.0000 - val_loss: 34573287424.0000\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 34196965376.0000 - val_loss: 34199310336.0000\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 33862961152.0000 - val_loss: 33931339776.0000\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 33551142912.0000 - val_loss: 33538342912.0000\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 33277290496.0000 - val_loss: 33203851264.0000\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 32920987648.0000 - val_loss: 32913336320.0000\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 32621393920.0000 - val_loss: 32583759872.0000\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 32279001088.0000 - val_loss: 32207814656.0000\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 31936073728.0000 - val_loss: 31891251200.0000\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 31622549504.0000 - val_loss: 31595403264.0000\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 31276759040.0000 - val_loss: 31203522560.0000\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 30965420032.0000 - val_loss: 30884427776.0000\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 30613204992.0000 - val_loss: 30516101120.0000\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 30290065408.0000 - val_loss: 30193862656.0000\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 29941757952.0000 - val_loss: 29827958784.0000\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 29595764736.0000 - val_loss: 29485987840.0000\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 29273491456.0000 - val_loss: 29118416896.0000\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 28933404672.0000 - val_loss: 28770861056.0000\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 28584114176.0000 - val_loss: 28455268352.0000\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 28243105792.0000 - val_loss: 28102436864.0000\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 27903264768.0000 - val_loss: 27747817472.0000\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 27563048960.0000 - val_loss: 27367665664.0000\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 27207153664.0000 - val_loss: 27036667904.0000\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 26856785920.0000 - val_loss: 26626471936.0000\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 26509752320.0000 - val_loss: 26292015104.0000\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 26161651712.0000 - val_loss: 25918996480.0000\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 25819076608.0000 - val_loss: 25555146752.0000\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 25470543872.0000 - val_loss: 25240473600.0000\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 25123729408.0000 - val_loss: 24842704896.0000\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 24782321664.0000 - val_loss: 24512235520.0000\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 24431675392.0000 - val_loss: 24142389248.0000\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 24071540736.0000 - val_loss: 23776118784.0000\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 23715207168.0000 - val_loss: 23437416448.0000\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 23371501568.0000 - val_loss: 23057686528.0000\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 23034847232.0000 - val_loss: 22743764992.0000\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 22697840640.0000 - val_loss: 22404204544.0000\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 22343704576.0000 - val_loss: 22008006656.0000\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 22015494144.0000 - val_loss: 21658695680.0000\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 21659125760.0000 - val_loss: 21294774272.0000\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 21313820672.0000 - val_loss: 20971028480.0000\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 20992989184.0000 - val_loss: 20605710336.0000\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 20654977024.0000 - val_loss: 20281309184.0000\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 20302112768.0000 - val_loss: 19943790592.0000\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 19977949184.0000 - val_loss: 19621298176.0000\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 19660687360.0000 - val_loss: 19265486848.0000\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 19339618304.0000 - val_loss: 18934779904.0000\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 19002644480.0000 - val_loss: 18624847872.0000\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 18687989760.0000 - val_loss: 18293260288.0000\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 18372184064.0000 - val_loss: 17969526784.0000\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 18087086080.0000 - val_loss: 17686163456.0000\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 17759225856.0000 - val_loss: 17352232960.0000\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 17450141696.0000 - val_loss: 17076389888.0000\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 17172748288.0000 - val_loss: 16774926336.0000\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 16859100160.0000 - val_loss: 16455168000.0000\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 16594952192.0000 - val_loss: 16211043328.0000\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 16300315648.0000 - val_loss: 15896598528.0000\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 16013664256.0000 - val_loss: 15620093952.0000\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 15748086784.0000 - val_loss: 15339834368.0000\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 15486252032.0000 - val_loss: 15081504768.0000\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 15222616064.0000 - val_loss: 14818966528.0000\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 14969814016.0000 - val_loss: 14584818688.0000\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 14732128256.0000 - val_loss: 14327294976.0000\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 14488970240.0000 - val_loss: 14095616000.0000\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 14255550464.0000 - val_loss: 13869796352.0000\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 14033907712.0000 - val_loss: 13641057280.0000\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13826146304.0000 - val_loss: 13434149888.0000\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13613122560.0000 - val_loss: 13223769088.0000\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13413211136.0000 - val_loss: 13030934528.0000\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13219819520.0000 - val_loss: 12838890496.0000\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13030433792.0000 - val_loss: 12653503488.0000\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12847700992.0000 - val_loss: 12476663808.0000\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12688583680.0000 - val_loss: 12314458112.0000\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12512317440.0000 - val_loss: 12152419328.0000\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12351302656.0000 - val_loss: 11998893056.0000\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12204038144.0000 - val_loss: 11857205248.0000\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12056484864.0000 - val_loss: 11717222400.0000\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11929831424.0000 - val_loss: 11588254720.0000\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11796948992.0000 - val_loss: 11464939520.0000\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11686115328.0000 - val_loss: 11355279360.0000\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11577740288.0000 - val_loss: 11249239040.0000\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11464429568.0000 - val_loss: 11145038848.0000\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11359491072.0000 - val_loss: 11052705792.0000\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11268589568.0000 - val_loss: 10968503296.0000\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11187356672.0000 - val_loss: 10894451712.0000\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11103287296.0000 - val_loss: 10817675264.0000\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11033119744.0000 - val_loss: 10761929728.0000\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10976661504.0000 - val_loss: 10678472704.0000\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10919044096.0000 - val_loss: 10643897344.0000\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10842445824.0000 - val_loss: 10571049984.0000\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10807523328.0000 - val_loss: 10511981568.0000\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10724203520.0000 - val_loss: 10465062912.0000\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10682463232.0000 - val_loss: 10426141696.0000\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10645150720.0000 - val_loss: 10387844096.0000\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10618933248.0000 - val_loss: 10357708800.0000\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10574912512.0000 - val_loss: 10349583360.0000\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10542645248.0000 - val_loss: 10300416000.0000\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10504851456.0000 - val_loss: 10271975424.0000\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10480206848.0000 - val_loss: 10253407232.0000\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10453728256.0000 - val_loss: 10249568256.0000\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10437792768.0000 - val_loss: 10210099200.0000\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10424314880.0000 - val_loss: 10220026880.0000\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10389831680.0000 - val_loss: 10185068544.0000\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10393304064.0000 - val_loss: 10177391616.0000\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10369037312.0000 - val_loss: 10157932544.0000\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10359200768.0000 - val_loss: 10155056128.0000\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10345946112.0000 - val_loss: 10140160000.0000\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10342317056.0000 - val_loss: 10135201792.0000\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10333329408.0000 - val_loss: 10128674816.0000\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10324184064.0000 - val_loss: 10121305088.0000\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10316009472.0000 - val_loss: 10116026368.0000\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10318197760.0000 - val_loss: 10123567104.0000\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10307222528.0000 - val_loss: 10109247488.0000\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10313684992.0000 - val_loss: 10152539136.0000\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10286006272.0000 - val_loss: 10101426176.0000\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10283110400.0000 - val_loss: 10120039424.0000\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10286624768.0000 - val_loss: 10098425856.0000\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10292753408.0000 - val_loss: 10129062912.0000\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10278705152.0000 - val_loss: 10122358784.0000\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10296778752.0000 - val_loss: 10094597120.0000\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10278360064.0000 - val_loss: 10094334976.0000\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10268023808.0000 - val_loss: 10130570240.0000\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10293240832.0000 - val_loss: 10103821312.0000\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10270372864.0000 - val_loss: 10093310976.0000\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10266488832.0000 - val_loss: 10134919168.0000\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10320175104.0000 - val_loss: 10171694080.0000\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259666944.0000 - val_loss: 10091639808.0000\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262136832.0000 - val_loss: 10115590144.0000\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10273177600.0000 - val_loss: 10103675904.0000\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10269626368.0000 - val_loss: 10098137088.0000\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260165632.0000 - val_loss: 10098567168.0000\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10263225344.0000 - val_loss: 10104004608.0000\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10266165248.0000 - val_loss: 10095252480.0000\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10261345280.0000 - val_loss: 10096923648.0000\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257766400.0000 - val_loss: 10090654720.0000\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10274161664.0000 - val_loss: 10105274368.0000\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263195648.0000 - val_loss: 10112124928.0000\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10258473984.0000 - val_loss: 10090906624.0000\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263933952.0000 - val_loss: 10094395392.0000\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10271962112.0000 - val_loss: 10095767552.0000\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10267199488.0000 - val_loss: 10096588800.0000\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10273964032.0000 - val_loss: 10104288256.0000\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10256948224.0000 - val_loss: 10091768832.0000\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10258437120.0000 - val_loss: 10094756864.0000\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10267369472.0000 - val_loss: 10096922624.0000\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10265907200.0000 - val_loss: 10097899520.0000\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10258353152.0000 - val_loss: 10100001792.0000\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10258443264.0000 - val_loss: 10115275776.0000\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260998144.0000 - val_loss: 10108968960.0000\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10265522176.0000 - val_loss: 10100180992.0000\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257482752.0000 - val_loss: 10100089856.0000\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10264697856.0000 - val_loss: 10114371584.0000\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257717248.0000 - val_loss: 10109240320.0000\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10286920704.0000 - val_loss: 10095741952.0000\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10265815040.0000 - val_loss: 10095705088.0000\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10288730112.0000 - val_loss: 10095133696.0000\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10283669504.0000 - val_loss: 10101519360.0000\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10285999104.0000 - val_loss: 10098873344.0000\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263680000.0000 - val_loss: 10097912832.0000\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261826560.0000 - val_loss: 10097281024.0000\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10273085440.0000 - val_loss: 10111994880.0000\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257531904.0000 - val_loss: 10100894720.0000\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10284701696.0000 - val_loss: 10107116544.0000\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10271080448.0000 - val_loss: 10106206208.0000\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10269954048.0000 - val_loss: 10098148352.0000\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261714944.0000 - val_loss: 10107364352.0000\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261890048.0000 - val_loss: 10096165888.0000\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10267136000.0000 - val_loss: 10097196032.0000\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10264087552.0000 - val_loss: 10113416192.0000\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10287358976.0000 - val_loss: 10098058240.0000\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10267472896.0000 - val_loss: 10095771648.0000\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260131840.0000 - val_loss: 10097122304.0000\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261761024.0000 - val_loss: 10096882688.0000\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260499456.0000 - val_loss: 10112927744.0000\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10267281408.0000 - val_loss: 10098222080.0000\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263258112.0000 - val_loss: 10155901952.0000\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10271965184.0000 - val_loss: 10111889408.0000\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262601728.0000 - val_loss: 10097168384.0000\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10256508928.0000 - val_loss: 10095961088.0000\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257485824.0000 - val_loss: 10117393408.0000\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262610944.0000 - val_loss: 10102056960.0000\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10254693376.0000 - val_loss: 10149469184.0000\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10275870720.0000 - val_loss: 10102052864.0000\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260756480.0000 - val_loss: 10104129536.0000\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259470336.0000 - val_loss: 10099732480.0000\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10264222720.0000 - val_loss: 10098604032.0000\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261178368.0000 - val_loss: 10108825600.0000\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10272474112.0000 - val_loss: 10106110976.0000\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10270092288.0000 - val_loss: 10103753728.0000\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262292480.0000 - val_loss: 10109096960.0000\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263913472.0000 - val_loss: 10103792640.0000\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260481024.0000 - val_loss: 10112635904.0000\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260931584.0000 - val_loss: 10111520768.0000\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10264614912.0000 - val_loss: 10104268800.0000\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10290359296.0000 - val_loss: 10131568640.0000\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10277648384.0000 - val_loss: 10103984128.0000\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263449600.0000 - val_loss: 10103545856.0000\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262420480.0000 - val_loss: 10111435776.0000\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262552576.0000 - val_loss: 10106647552.0000\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259921920.0000 - val_loss: 10106813440.0000\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10262684672.0000 - val_loss: 10186436608.0000\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10290104320.0000 - val_loss: 10133653504.0000\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10283350016.0000 - val_loss: 10096322560.0000\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10304808960.0000 - val_loss: 10097436672.0000\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261933056.0000 - val_loss: 10102781952.0000\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10281716736.0000 - val_loss: 10096832512.0000\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10283514880.0000 - val_loss: 10099419136.0000\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10274981888.0000 - val_loss: 10096944128.0000\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10271497216.0000 - val_loss: 10095670272.0000\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261616640.0000 - val_loss: 10096530432.0000\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10258779136.0000 - val_loss: 10153025536.0000\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10265686016.0000 - val_loss: 10095356928.0000\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10274397184.0000 - val_loss: 10114077696.0000\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263467008.0000 - val_loss: 10122628096.0000\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10274136064.0000 - val_loss: 10108464128.0000\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10275507200.0000 - val_loss: 10102039552.0000\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10277613568.0000 - val_loss: 10125883392.0000\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10288356352.0000 - val_loss: 10105682944.0000\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262537216.0000 - val_loss: 10102205440.0000\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259918848.0000 - val_loss: 10097126400.0000\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263017472.0000 - val_loss: 10096709632.0000\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259632128.0000 - val_loss: 10097183744.0000\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262465536.0000 - val_loss: 10099594240.0000\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10270666752.0000 - val_loss: 10098348032.0000\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262045696.0000 - val_loss: 10121775104.0000\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10258116608.0000 - val_loss: 10115731456.0000\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260013056.0000 - val_loss: 10095979520.0000\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10269814784.0000 - val_loss: 10107492352.0000\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10264844288.0000 - val_loss: 10101886976.0000\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10267648000.0000 - val_loss: 10095123456.0000\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10281314304.0000 - val_loss: 10104462336.0000\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10286277632.0000 - val_loss: 10127407104.0000\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261434368.0000 - val_loss: 10110367744.0000\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259265536.0000 - val_loss: 10099124224.0000\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257130496.0000 - val_loss: 10104680448.0000\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261533696.0000 - val_loss: 10094231552.0000\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10269625344.0000 - val_loss: 10097857536.0000\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261204992.0000 - val_loss: 10098166784.0000\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10282615808.0000 - val_loss: 10115633152.0000\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10268444672.0000 - val_loss: 10096421888.0000\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10271352832.0000 - val_loss: 10124097536.0000\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10272993280.0000 - val_loss: 10116470784.0000\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257035264.0000 - val_loss: 10096033792.0000\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260832256.0000 - val_loss: 10096054272.0000\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260972544.0000 - val_loss: 10119241728.0000\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10262759424.0000 - val_loss: 10096520192.0000\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10266518528.0000 - val_loss: 10096818176.0000\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10266047488.0000 - val_loss: 10102223872.0000\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257848320.0000 - val_loss: 10097880064.0000\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263947264.0000 - val_loss: 10106291200.0000\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10268302336.0000 - val_loss: 10099216384.0000\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260773888.0000 - val_loss: 10099238912.0000\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10265522176.0000 - val_loss: 10166116352.0000\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263895040.0000 - val_loss: 10099174400.0000\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10261871616.0000 - val_loss: 10099788800.0000\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10256945152.0000 - val_loss: 10106980352.0000\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10260718592.0000 - val_loss: 10098072576.0000\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10254213120.0000 - val_loss: 10138007552.0000\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10273625088.0000 - val_loss: 10115819520.0000\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10262326272.0000 - val_loss: 10101063680.0000\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10267141120.0000 - val_loss: 10097364992.0000\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10280772608.0000 - val_loss: 10095882240.0000\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10259512320.0000 - val_loss: 10123520000.0000\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10273544192.0000 - val_loss: 10144922624.0000\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262196224.0000 - val_loss: 10097173504.0000\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10272296960.0000 - val_loss: 10144934912.0000\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260838400.0000 - val_loss: 10097817600.0000\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261125120.0000 - val_loss: 10102533120.0000\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261067776.0000 - val_loss: 10098257920.0000\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10275158016.0000 - val_loss: 10105794560.0000\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10265568256.0000 - val_loss: 10096898048.0000\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262017024.0000 - val_loss: 10112877568.0000\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10261433344.0000 - val_loss: 10107633664.0000\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10260323328.0000 - val_loss: 10117786624.0000\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261743616.0000 - val_loss: 10099183616.0000\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259753984.0000 - val_loss: 10099024896.0000\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10262859776.0000 - val_loss: 10102654976.0000\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261381120.0000 - val_loss: 10107803648.0000\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10290820096.0000 - val_loss: 10095809536.0000\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10270613504.0000 - val_loss: 10105285632.0000\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10258087936.0000 - val_loss: 10108858368.0000\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10259683328.0000 - val_loss: 10098331648.0000\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10256678912.0000 - val_loss: 10101233664.0000\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10257539072.0000 - val_loss: 10120912896.0000\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10263587840.0000 - val_loss: 10113945600.0000\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10261981184.0000 - val_loss: 10096908288.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe80bb7310>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train.values,\n",
    "          validation_data=(x_test,y_test.values),\n",
    "          batch_size=128,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447fafe-0624-4083-8005-af1dd258f11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5e615-4f4e-4fe0-bf82-ca8c1a6639fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
